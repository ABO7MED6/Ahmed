{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.baraasallout.com/test.html'\n",
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extract (h1,h2,p,li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading1 = soup.find_all('h1')\n",
    "heading2 = soup.find_all('h2')\n",
    "paragraph= soup.find_all('p')\n",
    "list = soup.find_all('li')\n",
    "\n",
    "content = []\n",
    "\n",
    "for h1 in heading1:\n",
    "    content.append(['h1', h1.text.strip()])\n",
    "for h2 in heading2:\n",
    "    content.append(['h2', h2.text.strip()])\n",
    "for p in paragraph:\n",
    "    content.append(['p', p.text.strip()])\n",
    "for li in list:\n",
    "    content.append(['li', li.text.strip()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Type', 'Content']\n",
    "with open('Extract_Text_Data.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    writer.writerow(header)\n",
    "    \n",
    "    writer.writerows(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableHeader=['Product Name','Price','In Stock']\n",
    "table=soup.find('table')\n",
    "\n",
    "element=[]\n",
    "\n",
    "for row in table.find_all('tr')[1:]:\n",
    "    cells =row.find_all('td')\n",
    "    element.append([cells[0].text.strip(), cells[1].text.strip(), cells[2].text.strip()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Extract_Table_Data.csv','w',encoding='UTF8',newline='') as f:\n",
    "    writer= csv.writer(f)\n",
    "    \n",
    "    writer.writerow(tableHeader)\n",
    "    \n",
    "    writer.writerows(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Product Information (Card Section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Products = []\n",
    "\n",
    "productCards = soup.find_all('div', class_='product-card')\n",
    "\n",
    "for card in productCards:\n",
    "    title = card.find('p', class_='name').text.strip()\n",
    "    \n",
    "    price = card.find('p', class_='price').text.strip()\n",
    "    \n",
    "    colors = card.find('p', class_='colors').text.strip()\n",
    "    \n",
    "    button = card.find('button').text.strip()\n",
    "    \n",
    "    Products.append({\n",
    "        'Product Title': title,\n",
    "        'Price': price,\n",
    "        'Available ': colors,\n",
    "        'Button Text': button\n",
    "    })\n",
    "\n",
    "with open('Product_Information.JSON', 'w', encoding='utf-8') as f:\n",
    "    json.dump(Products, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Form to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 'Form_Input_Fields.JSON'\n"
     ]
    }
   ],
   "source": [
    "form = soup.find('form')\n",
    "\n",
    "input_fields = []\n",
    "\n",
    "for inputTag in form.find_all('input'):\n",
    "    fieldName = inputTag.get('name', 'Unnamed Field')\n",
    "    inputType = inputTag.get('type', 'text')\n",
    "    defaultValue = inputTag.get('value', '')\n",
    "\n",
    "    input_fields.append({\n",
    "        'Field Name': fieldName,\n",
    "        'Input Type': inputType,\n",
    "        'Default Value': defaultValue\n",
    "    })\n",
    "\n",
    "with open('Form_Input_Fields.JSON', 'w', encoding='utf-8') as f:\n",
    "    json.dump(input_fields, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Data successfully written to 'Form_Input_Fields.JSON'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Links and Multimedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_and_multimedia = []\n",
    "\n",
    "hyperlinks = soup.find_all('a')\n",
    "for link in hyperlinks:\n",
    "    href = link.get('href', '')\n",
    "    text = link.text.strip()\n",
    "    links_and_multimedia.append({\n",
    "        'Type': 'Hyperlink',\n",
    "        'Text': text,\n",
    "        'URL': href\n",
    "    })\n",
    "\n",
    "iframes = soup.find_all('iframe')\n",
    "for iframe in iframes:\n",
    "    src = iframe.get('src', '')\n",
    "    links_and_multimedia.append({\n",
    "        'Type': 'Video',\n",
    "        'URL': src\n",
    "    })\n",
    "\n",
    "with open('Links_And_Multimedia.JSON', 'w', encoding='utf-8') as f:\n",
    "    json.dump(links_and_multimedia, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Scraping Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": \"101\",\n",
      "        \"name\": \"Wireless Headphones\",\n",
      "        \"price\": \"$49.99\",\n",
      "        \"colors\": \"Black, White, Blue\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"102\",\n",
      "        \"name\": \"Smart Speaker\",\n",
      "        \"price\": \"$89.99\",\n",
      "        \"colors\": \"Grey, Black\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"103\",\n",
      "        \"name\": \"Smart Watch\",\n",
      "        \"price\": \"$149.99\",\n",
      "        \"colors\": \"Black, Silver, Gold\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "products = []\n",
    "\n",
    "product_cards = soup.find_all('div', class_='product-card')\n",
    "\n",
    "for card in product_cards:\n",
    "    productID = card.get('data-id')\n",
    "    productName = card.find('p', class_='name').text.strip()\n",
    "    productPrice = card.find('p', class_='price').text.strip()\n",
    "    productColors = card.find('p', class_='colors').text.replace('Available colors: ', '').strip()\n",
    "\n",
    "    products.append({\n",
    "        'id': productID,\n",
    "        'name': productName,\n",
    "        'price': productPrice,\n",
    "        'colors': productColors\n",
    "    })\n",
    "\n",
    "\n",
    "with open('Featured_Products.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(products, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
